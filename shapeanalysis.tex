
\chapter{Shape Analysis}
Pointers and heap-allocated storage are features of all modern imperative programming languages.
%they are ignored in most formal treatments of the semantics of imperative programming languages
%because their inclusion complicates the semantics of assignment statements: 
They are the most
\bjfix{the most}{among the most}
complicated features of imperative programming language:
%%\bjcom{Should be in plural}
Updating \bjcom{small cap after colon} pointer variables (or pointer-fields of records) may have large side effects.
%%\bjcom{skip ``on programs''}
For example, dereferencing a pointer that has been freed will lead to segmentation fault in a C or C++ program.
%Dereferencing NULL pointers and accessing previously deallocated storage are two common programming mistakes. The usage of pointers in programs is thus an obstacle for
%program understanding, debugging, and optimization. These activities need answers to many questions
%about the structure of the heap contents and the pointer variables pointing into the heap.
%
%\bjcom{This last sentence disturbs the flow. Change and move it til later}
These \bjcom{better ``Such''} side effects also make program analysis harder, because they make it
difficult to compute the \bjcom{skip ``the''} aliasing relationships among different pointers in a program. Aliasing refers to the case \bjfix{refers to the case}{arises} when the same memory location can be accessed using different names.
%\bjcom{Before the last sentence, explain what is aliasing}
For instance, consider the instruction \bjcom{instruction}{statement} $\tt x.f := y$ written \bjcom{omit ``written''} in an imperative language \bjcom{insert a comma} where $\tt x$ and $\tt y$ are pointer variables \bjcom{skip rest of the sentence} pointing to memory cells. Its effect is to assign the value of the pointer $\tt y$ to the pointer field $\tt f$ \bjcom{The rest of this sentence is VERY strange} of the cell pointed to by $\tt x$. In order to update aliasing information of $\tt y$. We have to require information about all cells pointed by $\tt x.f$ which is not an easy task.
\bjcom{The last two sentences do not make sense (e.g., x.f points to exactly one
  cell, so what means ``all cells''?). Make a new try}

In verification and program analysis, it is a problem to describe and deduce \bjcom{better ``deduce and describe''} how the heap-allocated memory is organized. E.g., Program \bjcom{Why capital P?} invariants must often describe how the heap-allocated memory is structured in order to infer the effects of statements that dereference pointer fields. This is the topic of ``shape analysis''.

%\bjcom{This last sentence is not understandable. I suggest you rewrite and make it less complicated. Find the simplest way to explain what is here some problem}
%Having less precise program dependence information
%\bjcom{You often use ``program dependence information'' without explaining what it means}
%decreases the opportunities for automatic parallelization
%and for instruction scheduling. 
%The usage of pointers is error prone.
%\bjcom{This last thing was more or less said in the beginning of the page}

 
%\bjcom{It is good to have an introductory paragraph, like this one, to give an idea of what are the challenges with pointers. But please rewrite it to have a more logical flow, and make the problems that you want to bring up clear}

%There exist several works that have treated the semantics of pointers such as works in [5, 42, 43, 45].

%\bjcom{A suggestion is to have: First a paragraph describing pointers and generla problems (aliasing, segmentation fault). A next paragraph can be to introduce that
%  in verification and program analysis, it is a problem to describe and deduce how the heap-allocated memory is organized. E.g., Program invariants must often
%  describe how the heap-allocated memory is structured in order to infer the effects of statements that dereference pointer fields. This is the topic of
%  ``shape analysis''}

\bjcom{First sentence must be rewritten}
By shapes, which mean descriptors of heap contents. Shape analysis is a generic term denoting static
program-analysis techniques that attempt to discover and verify properties of the heap contents in (usually imperative) software \bjcom{omit ``software''} programs. The shape analysis problem becomes more challengeing in concurrent programs thcat manipulate pointers and dynamically allocated objects, which are usually complicated. 
\bjcom{You did not propertly solve the comment: Why is it more interesting in ``concurrent programs''. I suggest it is because different threads interact in complex ways, which are difficult to foresee in the analysiso}
The problem of verifying these programs has been a subject of intense research for quite some time. Currently, there are several competing approaches for symbolic representation.
\bjcom{The last sentence was not good. Maybe something along the lines``Several approaches for representing the possible structures of the heap have been proposed''}
\input{heap-lazy-list}
 
TVLA (Three-Valued Logic Analyzer) \cite{SagivRW02} \bjfix{Analyzer}{Analysis} is \bjcom{insert ``one of''} the first and one of the most popular shape analysis
method. \bjcom{plural, please} It is based on a three-valued first-order predicate logic with transitive closure. Three-valued logic \bjcom{use ``TVLA''} is a logic system where there are three truth value ’true’ and ’false’, and ’unknown’. Intuitively, concrete heap structure is represented by a finite set of abstract summary cells, each of them representing a set of concrete cells. Summary cells are obtained by combining several heap cells that agree on the values of a chosen set of unary abstraction predicates. \bjcom{I think the explanation of summary cells should be improved to be understandable. You might consider putting a small illustration of what is a summary cell. I could also suggest to remove the text about
  ``three truth valueS'', since that is less important than the feature of wummary NODES (be careful with terms)}
A unique \bjfix{unique}{important} aspect of TVLA is that it automatically generates the abstract transformers from the concrete semantics; these transformers are guaranteed to be sound, and precise enough to verify wide ranges of applications. However,
The method is not fully automatic,
\bjcom{This is too strong. The core part can be fully automated. You might write that it cannot fully automatically handle all programs, and that one may have
  to extend it by appropriate predicates etc.} its the synthesis of appropriate predicates that are able to express the invariants in the program. This problem is even more difficult with complicated heap structures such as skip-lists, trees, or arrays of lists.  

Another approach is 
\bjcom{Better to start ``There are several other ...''}
 based on the use of logics to present heap configurations. The logics can be separation logic \cite{John:SL, Stephen:SL,JoshCris:SL,Hongseok:SL,Kamil:SL,Chin:SL,Quang:SL, Ruzica:SL, Constrantin:SL}, 3-valued logic \cite{SagivRW02} \bjcom{Why repeat it here?}, monadic second- order \bjcom{check how to separate or conjoin ``second'' ``order''} logic \cite{Ander:ML, Jakob:ML,Madhusudan:ML} or other \cite{Shmuel:Shape, Karen:Shape}. Among these works, the work, such as \cite{JoshCris:SL,Hongseok:SL, Quang:SL} proposed more efficient approaches. \bjcom{The preceding sentence had no information. You can improve it} The reason for that is that their approaches effectively decomposes \bjcom{Careful with singular/plural here} the heap into disjoint components and process \bjcom{bad word in this context} them independently). However, most of the techniques based on separation logic are either specialised for some particular data structure, or they need to be provided inductive definitions of the data structures. In addition, their entailment checking procedures are either for specific class of data structures or based on folding/unfolding inductive predicates in the formulae and trying to obtain a syntactic proof of the entailment. 

 %Another approach is based on the use of automata. In this approach, elements of languages of the automata describe configurations of the heap \cite{Ahmed:TreeAutomata, Ahmed:TreeAutomata2}. 
 
 This issue can be fixed \bjcom{Too strong. You could say ``addressed''} by automata \bjfix{automata}{automata-based} techniques using the generality of the automata-based representation such as techniques using tree automata. Finite tree automata, for instance, have been shown to provide a good balance between efficiency and expressiveness. The work \cite{Ahmed:TreeAutomata} uses a finite tree automaton to describe a set of heaps on a tree structure,
 bjcom{What means ``on a tree structure''?}
and represent non-tree edges by using regular “routing” expressions. These expressions
describe how the target can be reached from the source using tree edges.
\bjcom{``target''? ``source''?} 
Finite tree transducers
are used to compute set of reachable configurations, and symbolic configuration is abstracted
collapsing certain states of the automat. The refinement technique called counterexample-guided
abstraction refinement (CEGAR) technique is used during the run of the analysis. This technique
is fully automatically and can handle complex data structures such as binary trees with linked
leaves. However, it suffers from the inefficiency and it also can not handle concurrent programs.
\bjcom{The preceding paragraph was interesting, but too hard to follow. Try to
  explain in a more understandable way}

The problem of inefficiently of the previous technique can be solved by the approach based on forest automata. \bjcom{Put reference} In their \bjfix{their}{such as} representation, a heap is split in a canonical way into several tree components whose roots are the so-called cut-points. Cut-points are cells which are pointed to by either program variables or having several incoming edges. The tree components can refer to the roots of each other, and hence they are “separated” much like heaps described by formulae joined by the separating conjunction in separation logic [15]. \bjcom{Fix this citation in LATEX} Using this decomposition, sets of heaps with a bounded number of cut-points are then \bjfix{are then}{can then be} represented by the \bjcom{skip ``the''} so called forest automata (FA). A forest automaton (FA) \bjcom{You repeat the introduction of acronym} is basically a tuple of tree automata. Each of the tree
automata within the tuple accepts trees whose leaves may refer back to the
roots of any of these trees. A forest automaton then represents exactly the set
of heaps that may be obtained by taking a single tree from the language of each
of the component tree automata and by gluing the roots of the trees with the
leaves referring to them. \bjcom{Previous sentences was a good explanation. Now
  introduce the example, and discuss nested FAs only later}
 Moreover, they allow alphabets of FA to contain nested FA, leading to a hierarchical encoding of heaps, allowing us to represent even sets of heaps with an unbounded number of cut-points (e.g., sets of DLL, skiplist). \input FA
Let us take an example of how to split a heap into small tree components. Figure \ref{figure:forest} shows five tree components obtained by splitting the heap in figure \ref{lazy:list:heap:fig}. These components are named as 1,2,3,4 and 5 from left to right. Each root of a tree component is a cut-point in the heap in figure \ref{lazy:list:heap:fig}. These cut-points are cells pointed to by variables $\tt head$, $\tt tail$,  $\tt p$,  $\tt c$ and the cell which has two incoming pointers. In each tree component, the red node show which  tree component it refers. For instance, the tree component 1 refers to tree component 2, and both tree components 2 and 3 refer to tree component 4.
\bjcom{The number of pictures is buggy in preceding paragraph.
Check \url{http://www.terminally-incoherent.com/blog/2007/04/14/latex-fixing-wrong-figure-numbers/}}

This forest automata approach is fully automatic and able to verify various class \bjcom{put plural} of data structures \bjcom{put comma} including complicated structures such as trees and skip-lists. \bjcom{Not quite true for skip lists with unbounded heights?} However, the approach can not verify properties related to data values of heap cells such as sortedness in the lazy set algorithm. Therefore, in this thesis, we extend their work to verify data properties. 
\bjcom{This paragraph can be extended so that it mentions the challenges that
  you will address in papers I, II, and III: You can start from the FA approach
  and mention what it cannot do. Thereafter, you will have sections for each
  challenge in ``Our Approaches''. For instance, you can focus on
data in paper I, concurrency in Paper II, and non-SLL structures in paper III}

The last approach that we will mention is based on graph grammars describing heap graphs \cite{Jonathan:Shape, Jonathan:Grammars}. \bjcom{Please add a few sentence to describe the main ideas in these approaches} The presented approaches differ in their degree of specialisation for a particular class of data structures, their efficiency, and their level of dependence on user assistance (such as definition of loop invariants or inductive predicates for the considered data structures).
  
\section*{Our Approaches}
\bjcom{Use the present tense}
In this thesis, we proposed three approaches for heap abstractions. In paper I, we proposed a novel approach of representing sets of heaps via tree automata (TA). In our representation, a heap is split in a canonical way into several tree components whose roots are the so-called cut-points. Cut-points are nodes pointed to by program variables or having several incoming edges. The tree components can refer to the roots of each other, and hence they are “separated” much like heaps described by formulae joined by the separating conjunction in separation logic [15]. Using this decomposition, sets of heaps with a bounded number of cut-points are then represented by the so called forest automata (FA) that are basically tuples of TA accepting tuples of trees whose leaves can refer back to the roots of the trees. Moreover, we allow alphabets of FA to contain nested FA, leading to a hierarchical encoding of heaps, allowing us to represent even sets of heaps with an unbounded number of cut-points (e.g., sets of DLL, skiplist).
\bjcom{Separate the text so that previous FA work is in previous section (as
  you have now). In this section, you describe how you extend the FA approach}
 \input TA
 In addition, we express relationships between data elements associated with nodes of the heap graph \bjcom{Did you explain the term ``heap graph''?} by two classes of constraints.
 \bjcom{You can be more clear by putting bullets here: e.g., one for local and one for global}
 Local data constraints are associated with transitions of TA \bjfix{TA}{each TA} and capture relationships between data of neighboring nodes in a heap graph; they can be used, e.g., to represent ordering internal to some structure \bjcom{Be more specific than ``some structure''} such as a binary search tree. Global data constraints are associated with states of TA and capture relationships between data in distant parts of the heap.
 \bjcom{At this point, the text needs an illustration. Only thereafter you explain what the approach can accomplish}
This approach was applied to verification of sequential heap manipulation programs. This approach is general and fully automatic, it can handle many types of sequential programs without any manual step. However, due to the complexity of tree automata operations, this approach is not suitable to handle concurrent programs where a large number of states and computation are needed. Figure \ref{figure:forest} shows an example of how to represent a heap by a set of tree automata. Figure \ref{figure:forest}(a) shows an example of a heap where nodes whose values are \nodea, \nodeb, \nodec, \noded, \nodee \; are cut-points, and $\tt x$, $\tt y$, $\tt z$ are local pointer variables and $\tt g$ is global pointer variable. Figure \ref{figure:forest}(b) shows its forest representation. In the forest representation, there are five TAs in which the TAs \taa \; and \tac \; refer to the root of the last TA \tae\;, and both TAs \tab \; and \tad \; refer to the root of TA \tac \;. The local data constraints are located along the solid arrows between nodes, whereas global constraints are located along the dashed arrows. In this figure, the global constraints $\tt \prec_{aa}$ means that all nodes in the left hand side are smaller than all nodes in the right hand side. \bjcom{You can show how this applies to the lazy list example} We just show here small examples of data constraints, the detail about different types of constraints can be found in paper I.   

\bjcom{Here, a new (sub)section is needed}
In paper II, we provide a symbolic encoding of the heap structure, that is less precise than the approach in paper I. However it is precise enough to allow the verification of the concurrent algorithms, and efficient enough to make the verification procedure feasible in practice. \bjcom{The text that introduce paper II does not give a good picture. First of all, you must introduce the thread-modular
  approach, and illustrate it, i.e., one challenge is to cope with concurrency.
Thereafter, you can say that you need to adapt FA to the new setting.
You can say that your approach is now specialized for SLLs. You can introduce it by saying that TAs are replaced by ``heap segments''. (is it true that a heap
segment can be characterized by a TA with data constraints?).
Then you can explain whether cut points are now the same as for FAs or
whether they are different.}
The main idea of the abstraction is to have a more precise description of the parts of the heap that are visible (reachable) from global variables, and to make a succinct representation of the parts that are local to the threads. More concretely, we will extract a set of heap segments, where the end points of a segment is pointed to by a cut-point which is reachable from global variables. A cut-point in this approach is a reachable node from global variable, and pointed by a global variables or having more than two incoming pointers. For each segment, we will store a summary of the content of the heap along the segment. This summary consists of two parts, each part contains different pieces of information, including the values of the cell variables if they have finite values, and the ordering among them if they are integer variables. The first part summaries information between the end point and its predecessor, whereas the second part summaries information between the start point and the predecessor node. \bjcom{I could not understand the text in the preceding sentence} For each given program, the set of possible abstract shapes insight \bjcom{what do you mean here?} and hence the verification procedure is guaranteed to terminate.
\bjcom{In all descriptions, separate the text into more paragraphs. You can never
  have both explanation and assessment in the same. If you explain how the approach works, you can then illustrate. AFter that, you must make a new paragraph, where you can say what can be achieved with such an approach}
 This approach is very efficient but it is not optimal for complicated concurrent data structures like trees, lists of lists or skiplists. Figure \ref{heapsummary} gives our summary abstraction of the heap in figure \ref{figure:forest}(a). In this approach, \nodea, \nodeb, \nodec, \nodee \; are cut-points. The node \noded \; is not a cut-point like the approach in paper I because its not reachable from the global variable $\tt g$. In each heap segment, the fist part is described by the white box, and the second part is described by the gray box.   
\input SL
In paper III, we present an approach which can handle concurrent programs implemented from simple to complex data structures. \bjcom{Be more specific than this} In our fragment abstraction,
\bjcom{introduce the term ``fragment abstraction'' better, before you explain how it works} we represent the part of the heap that is accessible to a thread by a set of fragments. A fragment represents a pair of heap cells (accessible to $\thread$)
that are connected by a pointer field, under the applied data abstraction. The fragment contains both
(i) {\em local} information about the cell's fields and variables that
  point to it, as well as
(ii) {\em global} information, representing how
  each cell in the pair can reach to and be reached from
  (by following a chain of pointers) a small set of globally significant
  heap cells.
 A set of fragments represents the set of heap
structures in which each pair of pointer-connected nodes is represented by some
fragment in the set.
Put differently, a set of fragments describes the set of heaps that can be formed by
``piecing together'' pairs of pointer-connected nodes that are represented
by some fragment in the set. This ``piecing together'' must
be both locally consistent (appending only fragments that agree on their
common node), and globally consistent (respecting the global reachability
information).
\input fragment

Let us illustrate how pairs of heap nodes can be represented by fragments. Figure \ref{fragment} shows the set of fragments abstracted from the heap in \ref{figure:forest}(a). In each fragment, the ordering between two keys of two nodes is shown as a label on the arrow between two tags. Above each tag is pointer variables. The first brown row under each tag is $\tt reachfrom$ information, whereas the second green row is $\tt reachto$ information.

%To verify linearizability of the algorithm in Figure~\ref{figure:lazy-list},
%we must represent several key invariants of the heap. These include (among others)
%\begin{numberedlist}
%	\item The list is strictly sorted in $\tt key$ order, two unmarked nodes cannot have the same $\tt key$.
%\item All nodes which are unreachable from the head of the list are marked.
%\item The variable $\tt p$ points to a cells whose $\tt key$ field is never
%  larger than the input parameter of its $\tt add$,$\tt rmv$ and $\tt cnt$ methods.
%\end{numberedlist}
%Let us illustrate how such invariants are captured by our fragment abstraction. 1) All fragments are strictly sorted, implying that the list is strictly sorted. 2) This is verified by inspecting each tag: $\frag_{6}$ contains the only unreachable tag, and it is also marked. 3) The fragments express this property in the case where the value of $\tt key$ is the same as the value of the observer register $\tt x$. Since the invariant holds for any value of $\tt x$, this property is sufficiently represented for purposes of verification.   

\bjcom{After this, one would like to read about the point of fragment abstraction. Please show how it can be applied to skiplists}



