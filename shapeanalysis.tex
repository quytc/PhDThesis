
\chapter{Shape Analysis}
Pointers and heap-allocated storage are features of all modern imperative programming languages.
%they are ignored in most formal treatments of the semantics of imperative programming languages
%because their inclusion complicates the semantics of assignment statements: 
They are the most complicated features of imperative programming language:
%%\bjcom{Should be in plural}
Updating  pointer variables (or pointer-fields of records) may have large side effects.
%%\bjcom{skip ``on programs''}
For example, dereferencing a pointer that has been freed will lead to segmentation fault in a C or C++ program.
%Dereferencing NULL pointers and accessing previously deallocated storage are two common programming mistakes. The usage of pointers in programs is thus an obstacle for
%program understanding, debugging, and optimization. These activities need answers to many questions
%about the structure of the heap contents and the pointer variables pointing into the heap.
%
%\bjcom{This last sentence disturbs the flow. Change and move it til later}
These side effects also make program analysis harder, because they make it
difficult to compute the aliasing relationships among different pointers in a program. Aliasing refers to the case when the same memory location can be accessed using different names.
%\bjcom{Before the last sentence, explain what is aliasing}
For instance, consider the instruction $\tt x.f := y$ written in an imperative language where $\tt x$ and $\tt y$ are pointer variables pointing to memory cells. Its effect is to assign the value of the pointer $\tt y$ to the pointer field $\tt f$ of the cell pointed to by $\tt x$. In order to update aliasing information of $\tt y$. We have to require information about all cells pointed by $\tt x.f$ which is not an easy task.

In verification and program analysis, it is a problem to describe and deduce how the heap-allocated memory is organized. E.g., Program invariants must often describe how the heap-allocated memory is structured in order to infer the effects of statements that dereference pointer fields. This is the topic of ``shape analysis''.

%\bjcom{This last sentence is not understandable. I suggest you rewrite and make it less complicated. Find the simplest way to explain what is here some problem}
%Having less precise program dependence information
%\bjcom{You often use ``program dependence information'' without explaining what it means}
%decreases the opportunities for automatic parallelization
%and for instruction scheduling. 
%The usage of pointers is error prone.
%\bjcom{This last thing was more or less said in the beginning of the page}

 
%\bjcom{It is good to have an introductory paragraph, like this one, to give an idea of what are the challenges with pointers. But please rewrite it to have a more logical flow, and make the problems that you want to bring up clear}

%There exist several works that have treated the semantics of pointers such as works in [5, 42, 43, 45].

%\bjcom{A suggestion is to have: First a paragraph describing pointers and generla problems (aliasing, segmentation fault). A next paragraph can be to introduce that
%  in verification and program analysis, it is a problem to describe and deduce how the heap-allocated memory is organized. E.g., Program invariants must often
%  describe how the heap-allocated memory is structured in order to infer the effects of statements that dereference pointer fields. This is the topic of
%  ``shape analysis''}

By shapes, which mean descriptors of heap contents. Shape analysis is a generic term denoting static
program-analysis techniques that attempt to discover and verify properties of the heap contents in (usually imperative) software programs. The shape analysis problem becomes more challengeing in concurrent programs that manipulate pointers and dynamically allocated objects, which are usually complicated. 
%\bjcom{Why is it more interesting in ``concurrent programs''}
 The problem of verifying these programs has been a subject of intense research for quite some time. Currently, there are several competing approaches for symbolic representation. 
\input{heap-lazy-list}
 
TVLA (Three-Valued Logic Analyzer) \cite{SagivRW02} is the first and one of the most popular shape analysis
method. It is based on a three-valued first-order predicate logic with transitive closure. Three-valued logic is a logic system where there are three truth value ’true’ and ’false’, and ’unknown’. Intuitively, concrete heap structure is represented by a finite set of abstract summary cells, each of them representing a set of concrete cells. Summary cells are obtained by combining several heap cells that agree on the values of a chosen set of unary abstraction predicates. A unique aspect of TVLA is that it automatically generates the abstract transformers from the concrete semantics; these transformers are guaranteed to be sound, and precise enough to verify wide ranges of applications. However,
The method is not fully automatic, its the synthesis of appropriate predicates that are able to express the invariants in the program. This problem is even more difficult with complicated heap structures such as skip-lists, trees, or arrays of lists.  

Another approach is %\bjcom{I do not think this was the first} 
 based on the use of logics to present heap configurations. The logics can be separation logic \cite{John:SL, Stephen:SL,JoshCris:SL,Hongseok:SL,Kamil:SL,Chin:SL,Quang:SL, Ruzica:SL, Constrantin:SL}, 3-valued logic \cite{SagivRW02}, monadic second- order logic \cite{Ander:ML, Jakob:ML,Madhusudan:ML} or other \cite{Shmuel:Shape, Karen:Shape}. Among these works, the work, such as \cite{JoshCris:SL,Hongseok:SL, Quang:SL} proposed more efficient approaches. The reason for that is that their approaches effectively decomposes the heap into disjoint components and process them independently). However, most of the techniques based on separation logic are either specialised for some particular data structure, or they need to be provided inductive definitions of the data structures. In addition, their entailment checking procedures are either for specific class of data structures or based on folding/unfolding inductive predicates in the formulae and trying to obtain a syntactic proof of the entailment. 

 %Another approach is based on the use of automata. In this approach, elements of languages of the automata describe configurations of the heap \cite{Ahmed:TreeAutomata, Ahmed:TreeAutomata2}. 
 
This issue can be fixed by automata techniques using the generality of the automata-based representation such as techniques using tree automata. Finite tree automata, for instance, have been shown to provide a good balance between efficiency and expressiveness. The work \cite{Ahmed:TreeAutomata} uses a finite tree automaton to describe a set of heaps on a tree structure,
and represent non-tree edges by using regular “routing” expressions. These expressions
describe how the target can be reached from the source using tree edges. Finite tree transducers
are used to compute set of reachable configurations, and symbolic configuration is abstracted
collapsing certain states of the automat. The refinement technique called counterexample-guided
abstraction refinement (CEGAR) technique is used during the run of the analysis. This technique
is fully automatically and can handle complex data structures such as binary trees with linked
leaves. However, it suffers from the inefficiency and it also can not handle concurrent programs.

The problem of inefficiently of the previous technique can be solved by the approach based on forest automata. In their representation, a heap is split in a canonical way into several tree components whose roots are the so-called cut-points. Cut-points are cells which are pointed to by either program variables or having several incoming edges. The tree components can refer to the roots of each other, and hence they are “separated” much like heaps described by formulae joined by the separating conjunction in separation logic [15]. Using this decomposition, sets of heaps with a bounded number of cut-points are then represented by the so called forest automata (FA). A forest automaton (FA) is basically a tuple of tree automata. Each of the tree
automata within the tuple accepts trees whose leaves may refer back to the
roots of any of these trees. A forest automaton then represents exactly the set
of heaps that may be obtained by taking a single tree from the language of each
of the component tree automata and by gluing the roots of the trees with the
leaves referring to them. Moreover, they allow alphabets of FA to contain nested FA, leading to a hierarchical encoding of heaps, allowing us to represent even sets of heaps with an unbounded number of cut-points (e.g., sets of DLL, skiplist). \input FA
Let us take an example of how to split a heap into small tree components. Figure \ref{figure:forest} shows five tree components obtained by splitting the heap in figure \ref{lazy:list:heap:fig}. These components are named as 1,2,3,4 and 5 from left to right. Each root of a tree component is a cut-point in the heap in figure \ref{lazy:list:heap:fig}. These cut-points are cells pointed to by variables $\tt head$, $\tt tail$,  $\tt p$,  $\tt c$ and the cell which has two incoming pointers. In each tree component, the red node show which  tree component it refers. For instance, the tree component 1 refers to tree component 2, and both tree components 2 and 3 refer to tree component 4.

This forest automata approach is fully automatic and able to verify various class  of data structures including complicated structures such as trees and skip-lists. However, the approach can not verify properties related to data values of heap cells such as sortedness in the lazy set algorithm. Therefore, in this thesis, we extend their work to verify data properties. 

The last approach that we will mention is based on graph grammars describing heap graphs \cite{Jonathan:Shape, Jonathan:Grammars}. The presented approaches differ in their degree of specialisation for a particular class of data structures, their efficiency, and their level of dependence on user assistance (such as definition of loop invariants or inductive predicates for the considered data structures).
  
\section*{Our Approaches}
In this thesis, we proposed three approaches for heap abstractions. In paper I, we proposed a novel approach of representing sets of heaps via tree automata (TA). In our representation, a heap is split in a canonical way into several tree components whose roots are the so-called cut-points. Cut-points are nodes pointed to by program variables or having several incoming edges. The tree components can refer to the roots of each other, and hence they are “separated” much like heaps described by formulae joined by the separating conjunction in separation logic [15]. Using this decomposition, sets of heaps with a bounded number of cut-points are then represented by the so called forest automata (FA) that are basically tuples of TA accepting tuples of trees whose leaves can refer back to the roots of the trees. Moreover, we allow alphabets of FA to contain nested FA, leading to a hierarchical encoding of heaps, allowing us to represent even sets of heaps with an unbounded number of cut-points (e.g., sets of DLL, skiplist). \input TA
In addition, we express relationships between data elements associated with nodes of the heap graph by two classes of constraints. Local data constraints are associated with transitions of TA and capture relationships between data of neighboring nodes in a heap graph; they can be used, e.g., to represent ordering internal to some structure such as a binary search tree. Global data constraints are associated with states of TA and capture relationships between data in distant parts of the heap. This approach was applied to verification of sequential heap manipulation programs. This approach is general and fully automatic, it can handle many types of sequential programs without any manual step. However, due to the complexity of tree automata operations, this approach is not suitable to handle concurrent programs where a large number of states and computation are needed. Figure \ref{figure:forest} shows an example of how to represent a heap by a set of tree automata. Figure \ref{figure:forest}(a) shows an example of a heap where nodes whose values are \nodea, \nodeb, \nodec, \noded, \nodee \; are cut-points, and $\tt x$, $\tt y$, $\tt z$ are local pointer variables and $\tt g$ is global pointer variable. Figure \ref{figure:forest}(b) shows its forest representation. In the forest representation, there are five TAs in which the TAs \taa \; and \tac \; refer to the root of the last TA \tae\;, and both TAs \tab \; and \tad \; refer to the root of TA \tac \;. The local data constraints are located along the solid arrows between nodes, whereas global constraints are located along the dashed arrows. In this figure, the global constraints $\tt \prec_{aa}$ means that all nodes in the left hand side are smaller than all nodes in the right hand side. We just show here small examples of data constraints, the detail about different types of constraints can be found in paper I.   

In paper II, we provide a symbolic encoding of the heap structure, that is less precise than the approach in paper I. However it is precise enough to allow the verification of the concurrent algorithms, and efficient enough to make the verification procedure feasible in practice. The main idea of the abstraction is to have a more precise description of the parts of the heap that are visible (reachable) from global variables, and to make a succinct representation of the parts that are local to the threads. More concretely, we will extract a set of heap segments, where the end points of a segment is pointed to by a cut-point which is reachable from global variables. A cut-point in this approach is a reachable node from global variable, and pointed by a global variables or having more than two incoming pointers. For each segment, we will store a summary of the content of the heap along the segment. This summary consists of two parts, each part contains different pieces of information, including the values of the cell variables if they have finite values, and the ordering among them if they are integer variables. The first part summaries information between the end point and its predecessor, whereas the second part summaries information between the start point and the predecessor node. For each given program, the set of possible abstract shapes insight and hence the verification procedure is guaranteed to terminate. This approach is very efficient but it is not optimal for complicated concurrent data structures like trees, lists of lists or skiplists. Figure \ref{heapsummary} gives our summary abstraction of the heap in figure \ref{figure:forest}(a). In this approach, \nodea, \nodeb, \nodec, \nodee \; are cut-points. The node \noded \; is not a cut-point like the approach in paper I because its not reachable from the global variable $\tt g$. In each heap segment, the fist part is described by the white box, and the second part is described by the gray box.   
\input SL
In paper III, we present an approach which can handle concurrent programs implemented from simple to complex data structures. In our fragment abstraction, we represent the part of the heap that is accessible to a thread by a set of fragments. A fragment represents a pair of heap cells (accessible to $\thread$)
that are connected by a pointer field, under the applied data abstraction. The fragment contains both
(i) {\em local} information about the cell's fields and variables that
  point to it, as well as
(ii) {\em global} information, representing how
  each cell in the pair can reach to and be reached from
  (by following a chain of pointers) a small set of globally significant
  heap cells.
 A set of fragments represents the set of heap
structures in which each pair of pointer-connected nodes is represented by some
fragment in the set.
Put differently, a set of fragments describes the set of heaps that can be formed by
``piecing together'' pairs of pointer-connected nodes that are represented
by some fragment in the set. This ``piecing together'' must
be both locally consistent (appending only fragments that agree on their
common node), and globally consistent (respecting the global reachability
information).
\input fragment

Let us illustrate how pairs of heap nodes can be represented by fragments. Figure \ref{fragment} shows the set of fragments abstracted from the heap in \ref{figure:forest}(a). In each fragment, the ordering between two keys of two nodes is shown as a label on the arrow between two tags. Above each tag is pointer variables. The first brown row under each tag is $\tt reachfrom$ information, whereas the second green row is $\tt reachto$ information.

%To verify linearizability of the algorithm in Figure~\ref{figure:lazy-list},
%we must represent several key invariants of the heap. These include (among others)
%\begin{numberedlist}
%	\item The list is strictly sorted in $\tt key$ order, two unmarked nodes cannot have the same $\tt key$.
%\item All nodes which are unreachable from the head of the list are marked.
%\item The variable $\tt p$ points to a cells whose $\tt key$ field is never
%  larger than the input parameter of its $\tt add$,$\tt rmv$ and $\tt cnt$ methods.
%\end{numberedlist}
%Let us illustrate how such invariants are captured by our fragment abstraction. 1) All fragments are strictly sorted, implying that the list is strictly sorted. 2) This is verified by inspecting each tag: $\frag_{6}$ contains the only unreachable tag, and it is also marked. 3) The fragments express this property in the case where the value of $\tt key$ is the same as the value of the observer register $\tt x$. Since the invariant holds for any value of $\tt x$, this property is sufficiently represented for purposes of verification.   




