%% ====================================================================
\chapterwithtoc{Introduction}

Computers have been used for a variety of applications in business, science, education, engineering and so on. They help to solve real-world problems that would otherwise be slow, impossible or extremely difficult to address without computers and software. However, sometimes they do not behave exactly as we expect them. In many cases, the consequences could be very serious, for example when errors in banking or flight control software result in unexpected behaviours. Errors in computer systems are mostly not caused by the machine itself, but typically originate from the software that controls the computer systems, so-called bugs. Bugs are quite common in complex software systems since they typically have complicated input and involve many features, which makes them difficult to design and make them perfect by human effort. Detecting and fixing software bugs are important tasks in software development process. Remaining undetected bugs in any software project may lead huge problems. They can be very hard to detect and correct, especially if they are discovered after the software has been delivered. Therefore, it is very important to allocate sufficient resources, both in terms of time and manpower, to ensure that developed software is as free of bugs as possible. 

Some bugs are less serious than others. Some types of software, e.g., in user interfaces or entertainment software, can be useable even if it contains a small number of bugs.
However, in the case of critical systems and system components such as software in libraries of programming languages, 
bugs can have far-reaching consequences, and must be avoided as much as possible.
Some of libraries provide standard data structures such as stacks, queues, containers. Such data structures provide ways of storing  
and retrieving data in a way that suits the application at hand. For example, a stack allows inserting and removing elements in a particular order. Every time an element is inserted, that element is removed
in reverse order of insertion. The simplest application of a stack is to reverse a word. You insert a given word to stack - letter by letter - and then remove letters from the stack.
By using data structures data can be easily, and efficiently exchanged; it allows portability, comprehensibility, and adaptability of information.

A data structure can be both sequential or concurrent which is tricky and difficult to get correct. Concurrent data structures can be accessed and manipulated concurrently by many parallel threads are a central component of many parallel software applications. A data structure should ideally provide a simple interface to the software that uses it. An interface provides the set of operations with specifications about their types of arguments and returned values. Data structures typically use heap-allocated memory to store their data. For example, the concurrent linked queue in java.util.concurrent uses a singly linked list to organize their data. The data structure may be quite complex like skiplists and binary trees which are used to implement sets.

%\bjcom{Please extend this short paragraph to talk about complex features of data structure implementations, you can also include concurrency. Now the paragraph is too short}

The predominant method to ensure software quality is
\emph{testing}. It is a dynamic analysis where a program is executed under specific conditions, in so-called test cases, while checking whether the result for a given input matches the expected output.
%
The test cases should be carefully designed to cover as many as possible cases of program executions.
However, it is infeasible to cover all possible executions. Therefore, it is said by Edsger W. Dijkstra that testing can be used to show the presence of bugs, but never to show their absence. 
It would be nice to have techniques for checking that all executions conform to the interface of a data structure.
A possibility is to use formal techniques which is the approach used in this thesis.

%% ====================================================================
\section{Formal Verification} 
Formal verification uses mathematical methods to check whether a program, or piece of software satisfies its specification. 
There are several approaches to formal verification, including equivalence checking, theorem proving, and model checking. Equivalence checking method decides whether a system is equivalent to its specification with respect to some notion of equivalence. In industry, this is mostly used for hardware designs. Theorem proving is a technique where both the behavior of the system and its desired properties are expressed in mathematical logic. Then, theorem proving, typically assisted by an interactive theorem prover, will try to prove that the system satisfies these properties. 

Model checking takes as input a model of the program under
consideration and a formal specification of the a property to be verified as inputs. The specification of a software component may consist of a number of such properties, each of which can be verified using model checking. The approach exhaustively explores all possible executions of the model. This is typically done exploring the set of reachable states of the model  which can be finite or infinite. 
This works well if the set of reachable states is finite which typically happens for embedded controllers and hardware design. However, most softwares are infinite-state, e.g., a data structure may contain an unbounded amount of data. A common technique for handling this is to devise a symbolic representation of sets of states, such that a single symbolic representation represents an infinite set of states. 
%\bjcom{the rest of the paragraph is too simplistic: it does not give an adequate picture of the sota. Try to find a better (longer?) way to describe that work remains for model checking of data structure implementations} 
However, it is difficult to find a suitable symbolic representation for data structures. In particular, complicated data structures such as trees and skip-lists where relationship between heap cells are complicated in both reachability and data aspects.

%\bjcom{General comment: You must decorate the text with citations to relevant work, when this is called for. Examples are forest automtat, thread-modular, .. and
%there are many more. Please go over and add citations. These are needed so that the reader in the field understands what you are talking about}

\section{Research Challenges}
Our challenge of this thesis is to develop techniques for automated verification of both sequential and concurrent data structures using dynamically heap-allocated memory. This requires to address several challenges in model checking:
\begin{itemize}
\item {\bf Dynamically heap-allocated memory}: Data structures typically use dynamically heap allocated memory. In each cell of a heap, the domain of data values can be unbounded.
   In the area of formal verification, exist several approaches for heaps and for data, but not for combining them in suitable ways. In this thesis, we provide automate verification approach to sequential data structures where correctness depends on relationships between data values that are stored in the dynamically allocated structures. Such ordering relations on data are central for the operation of many data structures such as search trees, priority queues (based, e.g., on skip lists), key-value stores, or for the correctness of programs that perform sorting and searching. 
 There exist many automated verification techniques dealing with these data structures, but only few of them can automatically reason about data properties. However, they are often limited to specific classes of structures  mostly singly-linked lists (SLLs). Our approach is based on the notion of forest automata which has previously been developed for representing sets of reachable configurations of programs with complex dynamic linked data structures.

\item {\bf Unbounded number of threads}: For the case of concurrent data structures. We have to verify that the data structures are correct with any number of threads that access and manipulate the structures. We handle this challenge by extending the successfulthread-modular approach which verifies a concurrent program by generatingan invariant that correlates the global state with the local state of an arbitrary thread. By doing thread modular,  we only verify each thread
separately using an automatically inferred environment assumption that
abstracts the possible steps of other threads.
%\item \bjcom{Say what is the advantage/main point of thread-modular: E.g., why can it reduce infinite-state to finite-state?}
\item {\bf Specification of correctness}: To ensure that a concurrent data structure is correct, we have to specify a correctness criterion that relates the concurrent interface to the interface of a corresponding sequential data structure.  One way to capture such a correctness criterion is linearizability. Linearizability is generally accepted as the standard correctness criterion for such concurrent data structure implementations. Intuitively, it states that each operation on the concurrent data structure can be viewed as being performed atomically at some point (called linearization point (LP)) between its invocation and return. Existing approaches lack generality as they are limited to specific classes of concurrent data structures based on simple heaps such as singly linked lists, so far no technique (manual or automatic) for proving linearizability has been proposed that is both sound and generic. In this thesis we provide a technique to specify linearizability of concurrent data structures. 
\item {\bf Unbounded number of pointers}: In some data structures, the each cell can have unbound number of pointer fields,  such as cells in skip-lists and arrays of lists. It is difficult to provide symbolic representation for these data structures. There are no techniques that have been applied to automatically verify concurrent algorithms that operate on such data structures. We propose a technique called \emph{fragment abstraction} in which a heap is divided into small pieces called fragments. A fragment is an abstraction
of a pair of heap cells that are connected by a pointer field. Our approach is general and precise enough to verify these complicated data structures. 
%\bjcom{the last sentence was too vague and general. Be more precise (this comment applies throughout)}
\end{itemize}

%\bjcom{The following outline is too short. You should give an overview of the ``kappa'', in a way that now the reader understands what to expect in each
%chapter. Indirectly, the overview will also serve as a summary about the work you present}
The outline of the thesis is organized as follow: in the section 2, we present the general background about model checking, then in section 3, we describe data structures. Thereafter, in the following sections, we describe linearizability, how to specify them, and our heap abstraction techniques. In the last section, we summary and give future plans for our work.
