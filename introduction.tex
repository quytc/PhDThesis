%% ====================================================================
\chapterwithtoc{Introduction}

Computers have been used for a variety of applications in business, science, education, engineering and so on. They help to solve real-world problems that would otherwise be slow, impossible or extremely difficult to address without computers and software. However, sometimes they do not behave exactly as we expect them. In many cases, the consequences could be very serious, for example when errors in banking or flight control software result in unexpected behaviours. Errors in computer systems are mostly not caused by the machine itself, but typically originate from the software that controls the computer systems, so-called bugs. Bugs are quite common in complex software systems since they typically have complicated input and involve many features, which makes them difficult to design and make them perfect by human effort. Detecting and fixing software bugs are important tasks in software development process. Remaining undetected bugs in any software project may lead huge problems. They can be very hard to detect and correct, especially if they are discovered after the software has been delivered. Therefore, it is very important to allocate sufficient resources, both in terms of time and manpower, to ensure that developed software is as free of bugs as possible. 

Some bugs are less serious than others. Some types of software, e.g., in user interfaces or entertainment software, can be useable even if it contains a small number of bugs.
However, in the case of critical systems and system components such as software in libraries of programming languages, 
bugs can have far-reaching impacts \bjcom{skip ``impacts''} consequences, and must be avoided as much as possible.
Some of such \bjcom{skip ``of such''} libraries provide standard data structures such as stacks, queues, containers. Such data structures provide ways of storing  
and retrieving data in a way that suits the application at hand. For example, a stack allows adding and removing elements in a particular order. Every time an element is added, \bjfix{added}{inserted} it goes on the top of the stack, the only element that can be removed is the element that was at the top of the stack. \bjcom{I suggest to change the
description of stack to emphasize its INTERFACE: do not talk about the ``top'' of the stack, instead focus on the interface property that elements are removed
in reverse order of insertion} The simplest application of a stack is to reverse a word. You push a given word to stack - letter by letter - and then pop letters from the stack. \bjcom{Please be consistent: either insert/remove or push/pop or ... , but use the same always}
By using data structures data can be easily, and efficiently exchanged; it allows portability, comprehensibility, and adaptability of information.

A data structure can be both sequential or concurrent \bjcom{The rest of the sentence can be moved to the next paragraph and adapted} which is tricky and difficult to get correct. Concurrent data structures can be accessed and manipulated concurrently by many parallel threads are a central component of many parallel software applications. A data structure should ideally provide a simple interface to the software that uses it. An interface provides the set of supported operations along with specifications about what types of arguments of each operation and the value returned by each operation. \bjcom{Fix the grammar in preceding sentence} In order to implement this interface, the data structure may internally be quite complex.

Data structures typically use heap-allocated memory to store their data. For example, the concurrent linked queue in java.util.concurrent uses a singly linked list to organize their data. \bjcom{Please extend this short paragraph to talk about complex features of data structure implementations, you can also include
concurrency. Now the paragraph is too short}

The predominant method to improve \bjfix{improve}{ensure} software quality is
\emph{testing}. It is a dynamic analysis where a program is run \bjfix{run}{executed} under specific conditions, so-called \bjfix{so-called}{in so-called} test cases, and \bjfix{and}{while} checking whether the result with \bjfix{with}{for} a given input matches the expected output.
%
The test cases should be carefully designed to cover all possible cases of program executions.
\bjcom{Or ``as many as possible''}
\index{Coverage}
However, there is no guarantee \bjcom{better to say that it is infeasible to ..} to cover all possible executions. Therefore, it is said that
testing can be used to show the presence of bugs, but never to show their absence. \bjcom{Find the citation for this (Dijkstra, I believe)} 
It would be nice to have techniques for checking that all executions conform to the interface of a data structure,
\bjcom{Break the sentence}
a possibility is to use formal techniques which is the approach used in our \bjfix{our}{this} thesis.

%% ====================================================================
\section*{Formal Verification} 
Formal verification uses mathematical methods to check whether a software \bjcom{software}{program, or piece of software} satisfies its specification \bjcom{Skip rest of sentence} provided by users. 
There are several approaches for \bjfix{for}{to} formal verification, including equivalence checking, theorem proving, and model checking. Equivalence checking method decides whether a system is equivalent to its specification with respect to some notion of behavior \bjcom{skip ``behavior''} equivalence. This is mostly used for hardware designs\bjcom{Put ``in industry'' first in the sentence} in industry. Theorem proving is a technique where both the behavior of the system and its desired properties are expressed in mathematical logic. Then, theorem proving \bjcom{put the comma here} typically assisted by an interactive theorem prover \bjcom{add comma} will try to prove that the system satisfies these properties. 

Model checking takes as input a model of the system \bjcom{``software/program''?} under
consideration and a formal specification of the a property to be verified as inputs. The specification of a software component may consist of a number of such properties, each of which can be verified using model checking. The approach exhaustively explores all possible executions of the model. This is typically done exploring the set of reachable states of the model  which can be finite or infinite. 
This works well if the set of reachable states is finite such as \bjcom{such as}{which typically happens for embedded} controllers and hardware design. \bjcom{plural}  However, most software is infinite-state, e.g., a data structure may contain an unbounded amount of data -\bjcom{new sentence} a common technique for handling this is to devise a symbolic representation of sets of states, such that a single symbolic representation may represent \bjcom{may represent}{represents} an infinite set of states. \bjcom{the rest of the paragraph is too simplistic: it does not give an adequate picture of the sota. Try to find a better (longer?) way to describe that work remains for model checking of data structure implementations} However, it is difficult to find a suitable symbolic representation for data structures. In particular, complicated data structures such as trees and skip-lists.

\bjcom{General comment: You must decorate the text with citations to relevant work, when this is called for. Examples are forest automtat, thread-modular, .. and
there are many more. Please go over and add citations. These are needed so that the reader in the field understands what you are talking about}

\section*{Research Challenges}
Our challenge of this thesis is to develop techniques for automated verification of both sequential and concurrent data structures using heaps. \bjfix{heaps}{dynamically heap-allocated memory} This requires to address several challenges in model checking:
\begin{itemize}
\item {\bf Dynamically heap-allocated memory}: Heaps which are used by data structures \bjfix{Heaps which are used by data structures}{Data structures typically use} 
are dynamically heap allocated memory. In each cell of a heap, the domain of data values can be unbounded.
   The important aspect is \bjcom{Say that ``in the area of formal verification, exist ...''} that there
    exist several approaches for heaps and for data, but not for combining them in suitable ways. In this thesis, we automate its \bjcom{What means ``its''? please specify} application to sequential data structures where correctness depends on relationships between data values that are stored in the dynamically allocated structures. Such ordering relations on data are central for the operation of many data structures such as search trees, priority queues (based, e.g., on skip lists), key-value stores, or for the correctness of programs that perform sorting and searching. 
 There exist many automated verification techniques dealing with these data structures, in which \bjfix{in which}{but} only few of them can automatically reason about data properties. However, they are often limited to specific classes of structures  mostly singly-linked lists (SLLs). Our approach is based on the notion of forest automata which has previously been developed for representing sets of reachable configurations of programs with complex dynamic linked data structures.

\item {\bf Unbounded number of threads}: \bjcom{Say that this is ``for the case of concurrent data structures''} We have to verify that the data structures are correct with any number of threads that access and manipulate the structures. We handle the challenge of an unbounded number of threads \bjfix{the challenge of an unbounded number of threads}{this challenge} by extending the successfulthread-modular approach which verifies a concurrent program by generatingan invariant that correlates the global state with the local state of an arbitrarythread. \bjcom{Say what is the advantage/main point of thread-modular: E.g., why can it reduce infinite-state to finite-state?}
\item {\bf Specification of correctness}: To ensure that a concurrent data structure is correct, we have to ensure \bjcom{better ``specify a correctness criterion that relates the concurrent interface to the interface of a corresponding sequential data structure'' or something similar} that it respects to its sequential specification.  The correctness is captured by \bjcom{better ``one way to capture such a correctness criterion ...''} linearizability. Linearizability is generally accepted as the standard correctness criterion for such concurrent data structure implementations. Intuitively, it states that each operation on the concurrent data structure can be viewed as being performed atomically at some point (called linearization point (LP)) between its invocation and return. Existing approaches lack generality as they are limited to specific classes of concurrent data structures \bjcom{The preceding phrase is too general and vague, make it more precise and true} so far no technique (manual or automatic) for proving linearizability has been proposed that is both sound and generic. \bjcom{Break the preceding sentence} In this thesis we provide a technique to specify linearizabilities \bjcom{very strange term} of concurrent data structures. 
\item {\bf Unbounded number of pointers}: In some data structures, the each cell can have unbound number of pointer fields \bjcom{break the sentence here} such as cells in skip-lists and arrays of lists. It is difficult to provide symbolic representation for these data structures. There are no techniques that have been applied to automatically verify concurrent algorithms that operate on such data structures. We propose a technique called \emph{fragment abstraction} which is general and precise enough to verify these complicated data structures. \bjcom{the last sentence was too vague and general. Be more precise (this comment applies throughout)}
\end{itemize}

\bjcom{The following outline is too short. You should give an overview of the ``kappa'', in a way that now the reader understands what to expect in each
chapter. Indirectly, the overview will also serve as a summary about the work you present}
We present, in the next chapters, the general background about model checking, concurrent data structures. Thereafter, in the following chapter, we describe linearizabilities, how to specify them, and our symbolic representation techniques. In the last chapter, we summary and give future plans for our work.
