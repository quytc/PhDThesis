%% ====================================================================
\section*{Formal Verification} 
%Computer programs are written based on human intuition, which is probably leads to programming errors. Current practice is to test programs on various sample inputs in the hope of finding any possibility of incorrect program behavior. There exist many approaches like testing, simulation, static analysis and simple debugging techniques, such as inserting assertions and print statements in the source code, which show the presence of software errors. 

%Formal verification uses mathematical methods to verify whether a software satisfies its specification provided by users. 
%formal verification is the process of checking whether a software satisfies its predefined properties. 
Formal verification uses mathematical methods to check whether a software satisfies its specification provided by users. 
%formal verification is the process of checking whether a software satisfies its predefined properties. 
%\bjcom{Skip the following sentece. Continue into the next paragraph}
%There is a wide variety of specification to be checked for software programs, these specification can be very domain-specific, as in “train collisions and derailments do not occur in train traffic” or it may be generic, as in “no execution of the system dereferences a null pointer.” 
% be either safety or liveness properties. Liveness properties state that program execution eventually reaches several desirable states at some point of execution, for example liveness properties can be "the postman delivers the letter to the recipient", "A sent message is eventually received". In contract, verifying safety property of a program is satisfied is reduced to checking that something bad will never happen in the execution of the program [48]. 
%\input model
%In order to specify liveness properties, it is needed to  describe traces of events by using temporal logics, statistics, and probabilities. Checking aliveness property is done by repeatedly checking reachability of good situations in program executions. 
There are several approaches for formal verification, including equivalence checking, theorem proving, and model checking. Equivalence checking method decides whether a system is equivalent to its specification with respect to some notion of behavioral equivalence. This is \bjcom{Insert a sentence about where it is used. I think it is mostly used for hardware designs in industry} Theorem proving is a technique where both the \bjcom{insert ``behavior of the''} system and its desired properties are expressed in mathematicaal logic. Then, theorem proving \bjcom{insert ``typically assisted by an interactive theorem prover} will try to prove that the system satisfies these properties. 

Model checking approach take \bjfix{Model checking approach take}{Model checking takes as input} a model of the system under
consideration and a formal specification of the \bjfix{the}{a} property to be verified as inputs. \bjcom{Insert a sentence saying like ``The specification of a software component may consist of a number of such properties, each of which can be verified using model checking''}
The approach exhaustively explorer \bjcor{explores} all possible states  \bjcor{executions} of the model \bjcom{En the sentence here, and start a new one with ``This is typically done exploring the set of reachable states of the model''}  which can be finite or infinite \bjcom{Stop the sentence here, the stuff about infinite and abstraction comes later. Instead, start here by saying that this works well if the set of reachable states is finite, and also say in which application domains this has been successful} where infinite sets of states can be represented finitely by using abstraction techniques. In this way, it can be shown that a given system model truly satisfies a certain specification. Model checking is a general verification approach that is applicable to a wide range of applications
  such as embedded systems, software engineering, \bjcom{Skip ``software engineering''} and hardware design. However, it usually work well with finite-state systems. It is a real challenge to examine the largest possible state spaces that can be treated. For example, applying model checking to infinite-state systems such as data structures with many dimensions of infiniteness is a real challenge in current software verification research.
  \bjcom{The preceding paragraph needs better structure. You can use the flow: what is model checking - it works well for finite-state, e.g., for controllers and hardware design - most software is infinite-state, e.g., a data structure may contain an unbounded amount of data - a common technique for handling this is to devise a symbolic representation of sets of states, such that a single symbolic representation may represent an infinite set of states. Thereafter you can give an overview of
  what has been achieved using symbolic techniques}
%In this thesis though, we consider programs where the specification describes the bad behaviors. We concentrate on safety properties and try to design abstraction techniques to verify that a program including both sequential and concurrent program respects its specifications. 

%\section*{Verification of Data Structures}
%Most modern programming languages provide libraries of data structures such as the C++ Standard Template Library, the Java Collections Framework. A data structure is a particular way of organizing and storing data in a computer so that it can be accessed and modified efficiently. More precisely, a data structure is a collection of data values, the relationships among them, and operations that can be applied to the data. Each data structure has it own specification which describes the behaviour of the data structure. A data structure can be both sequential or concurrent, concurrent data structures can be accessed and manipulated concurrently by many parallel threads are a central component of many parallel software applications. They should allow a large degree of parallelism among accessing threads to minimize serialization bottlenecks, while maintaining the appearance of atomic operations. Many modern programming languages provide libraries of concurrent data structures (e.g., the java.util.concurrent package and Intel Threading Building Blocks library) that are widely used. 
%
%To ensure that a concurrent data structure is correct, we have to ensure that it respects to its sequential specification.  Ideally, the correctness is captured by linearizability. Linearizability is generally accepted as the standard correctness criterion for such concurrent data structure implementations. It states that each operation on the concurrent data structure can be viewed as being performed atomically at some point (called linearization point (LP)) between its invocation and return. The linearizability guarantee relieves the programmer from complex reasoning about possible interference among data-structure methods and removes the need to add explicit synchronization. Concurrent implementations of abstract data structures (stacks, queues, sets, etc.) are becoming more and more complex as implementations that increase the degree of concurrency are identified. This in turn is making linearizability verification harder. Existing approaches lack generality as they are limited to specific classes of concurrent data structures so far no technique (manual or automatic) for proving linearizability has been proposed that is both sound and generic. In this thesis, we focus on verifying safety properties including linearizability of both sequential and concurrent data structures.
\section*{Research Challenges}
%In this thesis, we consider two challenges in software verification, the first challenge is to automate its application to sequential programs that manipulate complex dynamic linked data structures. The problem becomes even more challenging when program correctness depends on relationships between data values that are stored in the dynamically allocated structures. Such ordering relations on data are central for the operation of many data structures such as search trees, priority queues (based, e.g., on skip lists), key-value stores, or for the correctness of programs that perform sorting and searching, etc. The challenge for automated verification of such programs is to handle both 
%\begin{challenges}
%\item infinite sets of reachable heap configurations and
%\item relationships between data values embedded in such graphs, 	
%\end{challenges}
%e.g., to establish sortedness properties, there exist many automated verification techniques, based on different kinds of logics, automata, graphs, or grammars, that handle these pointer structures. Most of these approaches abstract from properties of data stored in dynamically allocated memory cells. The few approaches that can automatically reason about data properties are often limited to specific classes of structures, mostly singly-linked lists (SLLs), and/or are not fully
%automated.
%
%We present a general framework for verifying programs with complex dynamic linked data structures whose correctness depends on relations between the stored data values. Our framework is based on the notion of forest automata (FA) which has previously been developed for representing sets of reachable configurations of programs
%with complex dynamic linked data structures [?]
\bjcom{Start by saying what is the overall challenge of your thesis. Then say that this requires to address several challenges in model checking}
In this thesis, we consider challenges in developing techniques for automated verification of both sequential and concurrent data structures using heaps. 
%Our challenges are to automate its application to both sequential and concurrent programs that manipulate complex dynamic linked data structures. We have to deal with concurrent programs with an unbounded number of threads that concurrently access and manipulate a dynamically allocated shared heap where data stored in each heap cell can be in unbound domain. Such programs and algorithms are difficult to get correct and verify, since their shapes are complicated to represent and they typically employ fine-grained synchronization, replacing locks by atomic operations such as compare-and-swap, and are therefore notoriously difficult to get correct, witnessed. It is therefore important to develop efficient techniques for automatically verifying their correctness. This requires overcoming several challenges. This thesis presents simple and efficient techniques to verify that a concurrent implementation of a common data type abstraction, namely queue, stack, set, conforms to a simple abstract specification of its (sequential) functionality. The data structures we consider for these programs can be singly-linked lists, sets of linked lists or skip-lists. In order to deal with this problem, we have to deal with several combined challenges as follow.
We have to deal with several sub-challenges as following: 
\bjcom{I suggest to use more standard bullets. Each bullet can have a number of letter, and have a heading of a few words, e.g, {\bf Dynamically heap-allocated memoty}. Also, do not just break the page here}
\bjcom{Each challenge should be described better. You must be more precise in what cannot be done with current techniques, and (on an abstract level) what you
  will try to achieve}
\newpage
\begin{challenges}
\item Heaps which are used by data structures are dynamically heap allocated memory. Therefore, we have to deal with unbounded number of heap cells. In this thesis, we propose three heap abstraction techniques to address the challenge, including forest automata, summary abstraction and view abstraction.
\item In each cell of a heap, the domain of data values can be unbounded. We use the combination of shape analysis and data abstraction to deal with this challenge. 
  \bjcom{I suggest to start with this challenge (since it is the first paper). You can start the preceding text and simplify it. The important aspect is that there
    are current approachs for heaps and for data, but not for combining them in suitable ways, and thereafter you describe very briefly your approach. Here is
    the disappeared text: ``In this thesis, we consider two challenges in software verification, the first challenge is to automate its application to sequential programs that manipulate complex dynamic linked data structures. The problem becomes even more challenging when program correctness depends on relationships between data values that are stored in the dynamically allocated structures. Such ordering relations on data are central for the operation of many data structures such as search trees, priority queues (based, e.g., on skip lists), key-value stores, or for the correctness of programs that perform sorting and searching, etc. The challenge for automated verification of such programs is to handle both 
\begin{itemize}
\item infinite sets of reachable heap configurations and
\item relationships between data values embedded in such graphs, 	
\end{itemize}
e.g., to establish sortedness properties, there exist many automated verification techniques, based on different kinds of logics, automata, graphs, or grammars, that handle these pointer structures. Most of these approaches abstract from properties of data stored in dynamically allocated memory cells. The few approaches that can automatically reason about data properties are often limited to specific classes of structures, mostly singly-linked lists (SLLs), and/or are not fully
automated''}

We present a general framework for verifying programs with complex dynamic linked data structures whose correctness depends on relations between the stored data values. Our framework is based on the notion of forest automata (FA) which has previously been developed for representing sets of reachable configurations of programs
with complex dynamic linked data structures [?]

\item We have to verify that the data structures are correct with any number of threads that access and manipulate the structures. We use the thread modular technique to dead with this challenge.
\item \bjcom{This paragraph should be improved. I suggest to make it the second challenge. You can start by saying that for concurrent data structures, you address
  a number of challenges, and then you have three bullets for each of them. The first is how to specify correctness in a way that is suitable for automated verification, the second is how to deal with an unbounded number of threads, the third is to provide a simple shape abstraction which can express relevant properties of different classes of heap structures: You can talk about skiplists, and their challenges}
To ensure that a concurrent data structure is correct, we have to ensure that it respects to its sequential specification.  Ideally, the correctness is captured by linearizability. Linearizability is generally accepted as the standard correctness criterion for such concurrent data structure implementations. It states that each operation on the concurrent data structure can be viewed as being performed atomically at some point (called linearization point (LP)) between its invocation and return. The linearizability guarantee relieves the programmer from complex reasoning about possible interference among data-structure methods and removes the need to add explicit synchronization. Concurrent implementations of abstract data structures (stacks, queues, sets, etc.) are becoming more and more complex as implementations that increase the degree of concurrency are identified. This in turn is making linearizability verification harder. Existing approaches lack generality as they are limited to specific classes of concurrent data structures so far no technique (manual or automatic) for proving linearizability has been proposed that is both sound and generic. In this thesis we provide a sound and generic technique to verify linearizabilities of concurrent data structures.
\item In some data structures, the each cell can have unbound number of pointer field such as cells in skip-lists and arrays of lists. This problem is solved by our fragment abstraction technique.
\end{challenges}

\bjcom{The outline must be more complete.}
We present, in the next chapters, the general background about model checking, concurrent data structures. Thereafter, in the following chapter, we introduce in a stepwise manner how
we cope with  above challenges. In the last chapter, we summary and give future plans for our work.
